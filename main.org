#+TITLE: *Big Data in Health Care*
#+AUTHOR: Federico Moiraghi - 799735, Pranav Kasela - 846965
#+DATE: A.A. 2019/2020
#+OPTIONS: toc:nil
#+LANGUAGE: it

#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, 12pt]

* Abstract :ignore:
#+begin_abstract
Obiettivo del presente Progetto è di fornire un modello predittivo che riesca a riconoscere i tumori omogenei da quelli eterogenei.
Infatti l'eterogeneità del tumore rappresenta una difficoltà aggiuntiva nella fase di trattamento, rendendolo maggiormente resistente alle cure.
Il modello risultante dal presente Progetto sarà facilmente interpretabile da un esperto di dominio, in modo tale da supportare le sue decisioni e non sostituirsi completamente ad esso.
#+end_abstract

* Indice :ignore:

#+TOC: headlines 1
#+LATEX: \thispagestyle{empty}
#+LATEX: \newpage


* Introduzione
Si è deciso di utilizzare per il presente Progetto il linguaggio di programmazione =R=, dato che il suo uso all'interno di ospedali e centri di ricerca è in forte crescita.
Grazie alla libreria [[https://cran.r-project.org/web/packages/RNifti/readme/README.html][=RNifti=]] è possibile importare i file =.nii= (contenenti le lesioni oncologiche), facilitando sia l'analisi esplorativa sia la successiva costruzione del modello.

#+BEGIN_SRC python :session :tangle yes :exports none :results none
import pandas as pd
from radiomics import featureextractor

#nii image reader
import SimpleITK as sitk
import numpy as np

import multiprocessing as mp
import os

#indicating the features required
extract_this = {"shape":      ["Maximum3DDiameter",
                               "MajorAxisLength", "Sphericity",
                               "MinorAxisLength", "SurfaceArea",
                               "SurfaceVolumeRatio",
                               "Flatness", "VoxelVolume"],
                "firstorder": ["Entropy", "Kurtosis","Maximum",
                               "MeanAbsoluteDeviation",
                               "Mean", "Median", "Minimum",
                               "MeanAbsoluteDeviation",
                               "Skewness", "Variance"],
                "glcm":       ["Autocorrelation", "Contrast"],
                "glrlm":      ["HighGrayLevelRunEmphasis"],
                "ngtdm":      ["Contrast", "Coarseness"]}

#initialize the featureextractor and define the required features
extractor = featureextractor.RadiomicsFeatureExtractor()
extractor.disableAllFeatures()
extractor.enableFeaturesByName(**extract_this)

features = ["diagnostics_Mask-original_VoxelNum"]
features_name = ["VoxelNum"]
for key in extract_this.keys():
    for elem in extract_this.get(key):
        features.append("original_"+key+"_"+elem)
        if key == "ngtdm":
            features_name.append(key+"_"+elem)
        else:
            features_name.append(elem)

features_name.append("y")

homImagePath = "./code__esempi/lesions/homogeneous/nifti/"
homImages = [(homImagePath+file,1) for file in os.listdir(homImagePath)]

hetImagePath = "./code__esempi/lesions/heterogeneous/nifti/"
hetImages = [(hetImagePath+file, 0) for file in os.listdir(hetImagePath)]

images = homImages + hetImages

def get_feature_df(path):
    img    = sitk.ReadImage(path[0])
    mask   = img > 0
    infos  = extractor.execute(img, mask)
    result = [float(infos[f]) for f in features]
    result.append(path[1])
    return result

#some parallelization (fede can increase the cpu count)
pool = mp.Pool(4)
res = pool.map(get_feature_df, images)

#the final df
final_df = pd.DataFrame(res, columns=features_name)

final_df.to_csv("feature_dataset.csv", index=None)
#+END_SRC

Caricate le immagini (si ha un esempio con figura [[section_example]]), si nota che queste rappresentano la lesione già segmentata.
Prima dell'analisi vera e propria è necessario ritagliare l'immagine, eliminando il valore dei /voxel/ esterni alla lesione: questi infatti hanno valore nullo, mentre, per aumentare l'efficienza del /workflow/, si preferisce eliminare tali valori rendendoli non definiti (=NA=).

#+BEGIN_SRC python :session :exports results :results file graphics :file images/sample.png
import matplotlib.pyplot as plt
x_1 = sitk.ReadImage(hetImages[14][0])
x = sitk.GetArrayFromImage(x_1)

fig = plt.figure()
count = 1
for z in range(x.shape[2]):
    if z>4 and z<14:
        plt.subplot(3,3,count)
        plt.imshow(x[:,:,z], cmap="gist_heat")
        plt.axis("off")
        count += 1

fig.savefig("./images/sample.png")
#+END_SRC

#+LABEL: section_example
#+CAPTION: Esempio di immagine. Essendo una figura tridimensionale, si rappresenta la profondità con più immagini.
#+RESULTS:
[[file:images/sample.png]]


Mentre le dimensioni dei /voxel/ sono fisse per tutti i files (tabella [[tbl_voxel_dim]]), l'immagine è ritagliata sulla lesione in modo specifico, tralasciando le parti adiacenti: le dimensioni variano in base alla dimensione della lesione stessa.

#+BEGIN_SRC python :session :exports results :results dataframe :rownames no :colnames yes
dim_x = x_1.GetMetaData("pixdim[1]")
dim_y = x_1.GetMetaData("pixdim[1]")
dim_z = x_1.GetMetaData("pixdim[1]")

res = pd.DataFrame({"x":[round(float(dim_x),3)],
                    "y":[round(float(dim_y),3)],
                    "z":[round(float(dim_z),3)]})

res
#+END_SRC

#+LABEL: tbl_voxel_dim
#+CAPTION: Dimensioni dei /voxel/ sugli assi $x$, $y$ e $z$.
#+RESULTS:
:        x      y      z
: 0  2.734  2.734  2.734

Dunque sarà importante estrarre delle /features/ che non dipendano dalla dimensione dell'immagine ma tengano conto di possibili variazioni.
Questo approccio comporta una serie di vantaggi, primo tra tutti la modularità del /workflow/: è possibile così prevedere la variabile risposta avendo a disposizione sia un'immagine già segmentata sia effettuando la segmentazione /on-the-fly/ tramite semplici algoritmi a soglia.

* Estrazione delle /features/
L'estrazione delle /features/ mappa le immagini in uno spazio di dimensionalità molto minore, rendendo più semplice l'analisi dato il numero esiguo di dati a disposizione.
Infatti, un qualsiasi algoritmo di /machine learning/ ha bisogno di un numero significativo di dati per  ``apprendere'' in modo /data-driven/ cosa utilizzare nell'analisi.

Per selezionare le /features/ da utilizzare, si è preso spunto da cite:imaging[fn::Gli autori usano i primi quattro momenti per stimare la differenza di eterogeneità di tumori alla cervicale nel tempo, a seguito di un trattamento.]: si usano i momenti dal primo fino al quarto (media, varianza, asimmetria e curtosi) dei valori dei /voxel/ che raffigurano la lesione oncologica.
A questi però si è deciso di aggiungere anche il volume della lesione (=volume=) e della sfera equivalente (=sphere=), così come anche la superficie (=area=) della lesione (figura [[tbl_features]]).
Purtroppo, non essendo stata specificata l'unità di misura dei /voxel/, non è possibile stabilirla nemmeno per le /features/ ricavate; tuttavia si presume che il proprietario dei dati sia in possesso di tale informazione e che quindi riesca ad attribuire maggiore semantica.

#+BEGIN_SRC R :session :tangle yes :exports results :results table :colnames yes
library(dplyr)

features <- read.csv("./feature_dataset.csv")
features <- features %>% mutate_at(setdiff(colnames(features),
                                           c("y")),
                                   ~(scale(.) %>% as.vector))

round(head(features), 3)
#+END_SRC

#+LABEL: tbl_features
#+CAPTION: Esempio di /features/ estratte per le singole immagini.
#+RESULTS:
| VoxelNum | Maximum3DDiameter | MajorAxisLength | Sphericity | MinorAxisLength | SurfaceArea | SurfaceVolumeRatio | Flatness | VoxelVolume | Entropy | Kurtosis | Maximum | MeanAbsoluteDeviation |   Mean | Median | Minimum | MeanAbsoluteDeviation.1 | Skewness | Variance | Autocorrelation | Contrast | HighGrayLevelRunEmphasis | ngtdm_Contrast | ngtdm_Coarseness | y |
|----------+-------------------+-----------------+------------+-----------------+-------------+--------------------+----------+-------------+---------+----------+---------+-----------------------+--------+--------+---------+-------------------------+----------+----------+-----------------+----------+--------------------------+----------------+------------------+---|
|    0.018 |            -0.695 |          -0.673 |      1.022 |          -0.266 |      -0.122 |             -0.658 |    1.037 |       0.018 |   0.035 |    0.451 |  -0.324 |                -0.732 |  0.138 |  0.216 |   1.783 |                  -0.732 |   -1.501 |   -0.688 |          -0.518 |   -0.721 |                   -0.512 |         -0.537 |            0.192 | 1 |
|   -0.661 |             0.436 |           0.812 |     -0.185 |          -1.274 |      -0.707 |              0.569 |   -1.317 |      -0.661 |   -0.82 |   -0.476 |  -1.065 |                -0.879 | -1.037 | -1.029 |  -1.052 |                  -0.879 |    0.478 |   -0.748 |          -0.712 |   -0.787 |                   -0.711 |         -0.531 |            1.026 | 1 |
|   -0.326 |            -0.719 |          -0.751 |      0.736 |          -0.525 |      -0.443 |             -0.254 |    0.527 |      -0.326 |   0.008 |   -0.616 |   0.707 |                 1.089 |  0.776 |  0.812 |   0.021 |                   1.089 |   -0.557 |    0.828 |           0.668 |    0.906 |                    0.641 |          0.782 |           -0.975 | 1 |
|    0.485 |             0.356 |           0.028 |      0.787 |            0.23 |       0.414 |             -0.901 |    0.767 |       0.485 |   0.907 |   -0.625 |   0.747 |                 1.021 |  0.659 |  0.731 |  -0.664 |                   1.021 |   -0.499 |    0.697 |           0.707 |    0.592 |                    0.686 |         -0.106 |           -0.995 | 1 |
|   -0.797 |            -0.986 |          -0.977 |      0.107 |          -0.913 |      -0.948 |                0.7 |   -0.128 |      -0.797 |  -1.033 |     0.76 |  -0.384 |                -0.594 | -0.188 | -0.171 |   0.051 |                  -0.594 |   -1.122 |   -0.605 |           -0.44 |   -0.671 |                    -0.44 |         -0.378 |            0.441 | 1 |
|    0.493 |            -0.236 |          -0.338 |      1.258 |           0.063 |       0.305 |             -1.037 |    1.274 |       0.493 |   0.509 |   -0.621 |  -0.592 |                -0.557 | -0.351 |  -0.25 |   0.139 |                  -0.557 |   -0.871 |    -0.63 |          -0.547 |   -0.688 |                   -0.546 |         -0.543 |           -0.063 | 1 |


La matrice dei dati risultante è quindi di dimensioni $44 \times 24$ (si esclude la variabile risposta), indipendentemente dalla dimensione delle immagini di partenza o dalla loro risoluzione.

Prima di procedere con la costruzione del modello, si preferisce effettuare una rapida analisi esplorativa sulla nuova matrice per verificare quali varibili includere.

Il primo metodo della feature selection e' usando il test di Mann-Whitney, equivalente non parametrico del t-test.
#+BEGIN_SRC R :session :tangle yes :exports results :results table :colnames yes
score <- c()
for (i in seq(1,dim(features)[2]-1)){
  formula <- paste0(colnames(features)[i]," ~ y")
  t_score <- wilcox.test(formula=as.formula(formula),
                    data=features)$p.value
  score <- c(score, round(t_score,3))
}
score_df <- data.frame(t(score))
colnames(score_df) <- colnames(features)[1:dim(features)[2]-1]
accepted <- colnames(score_df[,score_df < 0.05])

features <- features[,c(accepted, "y")]

score_df[,accepted]
#+END_SRC

#+CAPTION: p-values delle varibili accetate dal test di Mann-Whitney.
#+RESULTS:
| Maximum3DDiameter | MajorAxisLength | Sphericity | MinorAxisLength | SurfaceArea | Kurtosis | Maximum | Skewness | Variance | Contrast | ngtdm_Coarseness |
|-------------------+-----------------+------------+-----------------+-------------+----------+---------+----------+----------+----------+------------------|
|             0.011 |           0.012 |      0.003 |           0.003 |       0.016 |    0.002 |   0.008 |     0.04 |    0.025 |     0.02 |            0.034 |

Una volta scelto le variabili importanti vediamo la loro correlazione, per escluderle, questo e' necessario per evitare problemi di multicollinearita'.

#+BEGIN_SRC R :session :exports results :results file graphics :file images/corrplot.png
library(ggcorrplot)
ggcorrplot::ggcorrplot(
              cor(features),
              type = "lower",
              outline.col = "white",
              lab = TRUE)
#+END_SRC

#+LABEL: features_corr
#+CAPTION: Correlogramma delle /features/ estratte.
#+RESULTS:
[[file:images/corrplot.png]]

Dalla figura [[features_corr]], deduciamo subito che il Maximum e Variance sono correlati a piu' di una variabile, quindi e' meglio escluderli.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
new_cols <- setdiff(colnames(features),
                    c("Maximum","Variance",
                      "Maximum3DDiameter",
                      "MinorAxisLength",
                      "Contrast", "Sphericity"))

features <- features[,new_cols]
#+END_SRC
* Costruzione del modello
Essendo la variabile risposta binaria (tumore /omogeneo/ o /eterogeneo/, rispettivamente 0 o 1), e volendo costruire un modello facilmente interpretabile per un esperto di dominio, si effettua una semplice regressione logistica.
#+BEGIN_SRC R :session :tangle yes :exports none :results none
library(MASS)


accuracy <- function(y_true, y_hat) {
  return(mean(y_true == y_hat))
}

precision <- function(y_true, y_hat) {
  tp <- mean(y_hat == 1 & y_true == 1)
  fp <- mean(y_hat == 1 & y_true == 0)
  return(tp / (tp + fp))
}

recall <- function(y_true, y_hat) {
  tp <- mean(y_hat == 1 & y_true == 1)
  fn <- mean(y_hat == 0 & y_true == 1)
  if (fn == 0) return(1)
  return(tp / (tp + fn))
}

f1 <- function(y_true, y_hat) {
  p <- precision(y_true, y_hat)
  r <- recall(y_true, y_hat)
  return(2 * p * r / (p + r))
}


k <- 30
dim_fold <- 9
out <- list(accuracy = c(),
            precision = c(),
            recall = c(),
            f_1 = c())
features$y <- as.factor(features$y)
for (i in seq(1, k)) {
  set.seed(i)
  test_index <- sample(seq(1,dim(features)[1]), dim_fold)
  train_set <- features[-test_index, ]
  test_set  <- features[ test_index, ]

  mod <- glm(y ~ SurfaceArea + Kurtosis + Skewness,
             data = train_set,
             family = binomial("logit"))

  y_hat <- ifelse(predict(mod, test_set)>0.5, 1, 0)
  y_true <- test_set$y
  out$accuracy <- c(out$accuracy, accuracy(y_true, y_hat))
  out$precision <- c(out$precision, precision(y_true, y_hat))
  out$recall <- c(out$recall, recall(y_true, y_hat))
  out$f_1 <- c(out$f_1, f1(y_true, y_hat))
}
#+END_SRC
#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
out_df <- data.frame(index = c("accuracy", "precision", "recall", "f_1"))
scores <- c()
idc <- c()
for (index in out_df$index) {
  score <- out[[index]]
  score <- score[!is.nan(score)]
  mu <- mean(score)
  s  <- sd(score)
  d <- qt(0.99, length(score) - 1) * s / sqrt(length(score))
  scores <- c(scores, mu)
  idc <- c(idc, d)
}
out_df$average <- scores
out_df$IDC_99   <- idc
rownames(out_df) <- out_df$index
round(out_df[, c("average", "IDC_99")], 3)
#+END_SRC

#+RESULTS:
|           | average | IDC_99 |
|-----------+---------+--------|
| accuracy  |   0.863 |  0.045 |
| precision |    0.92 |  0.052 |
| recall    |   0.853 |   0.07 |
| f_1       |   0.873 |  0.046 |

La selezione delle /features/ è effettuata tramite procedimento /stepwise/ (partendo dal modello pieno ed eliminando le variabili superflue, ma con la possibilità, a ogni iterazione, di reinserirle).
Si è deciso di rimuovere alcune variabili a prescindere:
- =sd= (la varianza della distribuzione della lesione), in quanto fortemente correlata con =mean= (0.93) e di più difficile interpretazione;
- =area= (la superficie della lesione), in quanto la sua stima è approssimativa e risulta essere eccessivamente correlata ad altri regressori, inquinando eccessivamente la qualità dei dati;
- =sphere= (il volume della sfera equivalente), data la sua forte correlazione con la variabile =volume= (0.86) e la più difficile interpretabilità.
#+LATEX: \newline
Avendo a disposizione pochi dati, il procedimento è effettuato con l'indice AIC, che considera la capacità di generalizzazione del modello complessivo risultante (salvo poi verificare le /performance/ su un /test set/ composto da dati nuovi, rappresentante circa il 20% di quelli totali).
Alla fine del procedimento, il modello risultante comprende solo tre regressori (più l'intercetta), come mostrato in tabella [[tbl_model_coeff]].

#+BEGIN_SRC R :session :exports results :results tabular :colnames yes :rownames yes
df <- summary(mod)$coefficients[, c(1, 4)]
colnames(df) <- c("Stima", "p-value")
round(df, 6)
#+END_SRC

#+LABEL: tbl_model_coeff
#+CAPTION: Stima dei coefficienti del modello e loro significatività.
#+RESULTS:
|                   |      Stima |  p-value |
|-------------------+------------+----------|
| (Intercept)       |  -23.02822 | 0.999629 |
| Maximum3DDiameter |  59.690072 |  0.99963 |
| MajorAxisLength   | -49.874006 | 0.999685 |
| Sphericity        | -21.116633 | 0.999838 |
| MinorAxisLength   | -62.728735 | 0.999613 |
| SurfaceArea       | -62.645378 | 0.999723 |
| Kurtosis          | -77.175109 | 0.999154 |
| Skewness          | -62.668665 | 0.999299 |
| Contrast          |  11.717566 | 0.999757 |
| ngtdm_Coarseness  |  31.235255 | 0.999643 |


Si noti come i coefficienti maggiormente significativi siano l'asimmetria =sk= e il volume =volume=: la probabilità che il tumore sia eterogeneo è tanto maggiore quanto più grande è la lesione e quanto più pesante è la coda positiva della distribuzione.
Si può ipotizzare infatti che questa coda positiva sia costituita da sotto-componenti particolarmente aggressivi del tumore, quindi ``ghiotti'' di traccianti e di conseguenza maggiormente visibili nell'immagine.

#+BEGIN_SRC R :session :exports results :results tabular :colnames yes :rownames yes
previsions <- data.frame(prevision = ifelse(predict(mod, test_set) > 0.5,
                                            "heterogeneous",
                                            "homogeneous"),
                         real = ifelse(test_set$y == 1,
                                       "heterogeneous",
                                       "homogeneous"))
conf_matrix <- table(previsions)
#+END_SRC

#+LABEL: mod_confusion_matrix
#+CAPTION: Matrice di confusione del modello di regressione logistica per il /test set/; sulle righe le previsioni e sulle colonne i valori reali.
#+RESULTS:
|             | homogeneous |
|-------------+-------------|
| homogeneous |           4 |


Come si può notare nella matrice di confusione (figura [[mod_confusion_matrix]]), il modello ha commesso un solo errore catalogando come eterogenea una lesione omogenea.

#+BEGIN_SRC R :session :exports results :results tabular :rownames yes
accuracy  <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- conf_matrix["heterogeneous", "heterogeneous"] /
                  sum(conf_matrix["heterogeneous", ])
recall    <- conf_matrix["heterogeneous", "heterogeneous"] /
                  sum(conf_matrix[, "heterogeneous"])
f1        <- 2 * (precision * recall) / (precision + recall)
round(c("accuracy" = accuracy,
        "precision" = precision,
        "recall" = recall,
        "f_1" = f1), 2)
#+END_SRC

#+RESULTS:

#+LABEL: mod_results
#+CAPTION: Indici di accuratezza per il modello.
#+RESULTS:


* Conclusioni
Con questo Progetto si è costruito un modello statistico efficace e facilmente interpretabile da un esperto di dominio per prevedere l'eterogeneità del tumore.
Si è visto che, estrapolando dall'immagine dei semplici valori indice, è possibile costruire un modello indipendente dalla dimensione dell'immagine o dalla sua risoluzione.
#+LATEX: \newline
A livello matematico si potrebbe aumentare la prestazione del modello stimando i parametri con un numero maggiore di dati; tuttavia, in ambito medico, questo non è sempre possibile (anche perché, come espresso in cite:imaging, è possibile verificare l'eterogeneità del tumore solo in modo invasivo o con autopsia).
Inoltre si potrebbero utilizzare nuove /features/, soprattutto se utili ai fini della ricerca medica.
#+BEGIN_SRC R :session :tangle yes :exports none :results none
summary(mod)
#+END_SRC


* Bibliografia :ignore:
 #+LATEX: \newpage
#+LATEX: \nocite{*}
bibliographystyle:unsrt
bibliography:./bibliografia.bib
#+BEGIN_SRC bibtex :tangle bibliografia.bib :exports none
@article{imaging,
  author = {Bowen, Stephen and
            Yuh, William and
            Hippe, Daniel and
            Wu, Wei and
            Partridge, Savannah and
            Elias, Saba and
            Jia, Guang and
            Huang, Zhibin and
            Sandison, George and
            Nelson, Dennis and
            Knopp, Michael and
            Lo, Simon and
            Kinahan, Paul and
            Mayr, Nina},
  year = {2017},
  month = {10},
  pages = {},
  title = {Tumor radiomic heterogeneity: Multiparametric functional imaging to characterize variability and predict response following cervical cancer radiation therapy},
  volume = {47},
  journal = {Journal of Magnetic Resonance Imaging},
  doi = {10.1002/jmri.25874}
}
#+END_SRC
#+begin_comment
Local variables:
org-latex-caption-above: nil
End:
#+end_comment
