#+TITLE: *Big Data in Health Care*
#+AUTHOR: Federico Moiraghi - 799735 & Pranav Kasela - 846965
#+DATE: A.A. 2019/2020
#+OPTIONS: toc:nil
#+LANGUAGE: it

#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, 12pt]

* Abstract :ignore:
#+begin_abstract
Obiettivo del presente Progetto è di fornire due modelli predittivi che riescano a riconoscere i tumori omogenei da quelli eterogenei.
Infatti l'eterogeneità del tumore rappresenta una difficoltà aggiuntiva nella fase di trattamento, rendendolo maggiormente resistente alle cure.
Il primo modello, /supervised/, sarà facilmente interpretabile da un esperto di dominio, in modo tale da supportare le sue decisioni senza sostituirsi completamente ad esso.
Tale modello sarà poi confrontato con uno /unsupervised/, che sottolinea le analogie tra i singoli casi.
#+end_abstract

* Indice :ignore:

#+TOC: headlines 1
#+LATEX: \thispagestyle{empty}
#+LATEX: \newpage


* Introduzione
Si è deciso di sviluppare il presente Progetto coi linguaggi di programmazione Python ed R, data la forte crescita del loro uso sia in ambiente accademico che produttivo.
Il primo è usato soprattutto per l'estrazione delle /features/ dalle immagini, grazie alla libreria [[https://github.com/Radiomics/pyradiomics][=pyradiomics=]] che offre numerosi algoritmi, mentre il secondo per l'analisi dei dati, data l'ampia scelta di modelli di /machine learning/.

#+BEGIN_SRC python :session :tangle yes :exports none :results none
import pandas as pd
from radiomics import featureextractor

#nii image reader
import SimpleITK as sitk
import numpy as np

import multiprocessing as mp
import os

#indicating the features required
extract_this = {"shape":      ["Maximum3DDiameter",
                               "MajorAxisLength", "Sphericity",
                               "MinorAxisLength", "SurfaceArea",
                               "SurfaceVolumeRatio",
                               "Flatness", "VoxelVolume"],
                "firstorder": ["Entropy", "Kurtosis", "Maximum",
                               "MeanAbsoluteDeviation",
                               "Mean", "Median", "Minimum",
                               "MeanAbsoluteDeviation",
                               "Skewness", "Variance"],
                # "glcm":       ["Autocorrelation", "Contrast"],  # TODO: uncomment
                # "glrlm":      ["HighGrayLevelRunEmphasis"],     # TODO: uncomment
                "ngtdm":      ["Contrast", "Coarseness"]}

#initialize the featureextractor and define the required features
extractor = featureextractor.RadiomicsFeatureExtractor()
extractor.disableAllFeatures()
extractor.enableFeaturesByName(**extract_this)

features = ["diagnostics_Mask-original_VoxelNum"]
features_name = ["VoxelNum"]
for key in extract_this.keys():
    for elem in extract_this.get(key):
        features.append("original_" + key + "_" + elem)
        if key == "ngtdm":
            features_name.append(key + "_" + elem)
        else:
            features_name.append(elem)

features_name.append("y")

homImagePath = "./code__esempi/lesions/homogeneous/nifti/"
homImages = [(homImagePath+file, 1) for file in os.listdir(homImagePath)]

hetImagePath = "./code__esempi/lesions/heterogeneous/nifti/"
hetImages = [(hetImagePath+file, 0) for file in os.listdir(hetImagePath)]

images = homImages + hetImages

def get_feature_df(path):
    img    = sitk.ReadImage(path[0])
    mask   = img > 0
    infos  = extractor.execute(img, mask)
    result = [float(infos[f]) for f in features]
    result.append(path[1])
    return result

#some parallelization
pool = mp.Pool(4)
res = pool.map(get_feature_df, images)

#the final df
final_df = pd.DataFrame(res, columns=features_name)

# final_df.to_csv("feature_dataset.csv", index=None)  # TODO: uncomment
#+END_SRC

Caricate le immagini (si ha un esempio con figura [[section_example]]), si nota che queste rappresentano la lesione già segmentata.
Non si ritiene dunque necessaria alcuna forma particolare di /pre-processing/ sull'immagine.

#+BEGIN_SRC python :session :exports results :results file graphics :file images/sample.png
import matplotlib.pyplot as plt


x_1 = sitk.ReadImage(hetImages[14][0])
x = sitk.GetArrayFromImage(x_1)

fig = plt.figure()
count = 1
for z in range(x.shape[2]):
    if z > 4 and z < 14:
        plt.subplot(3, 3, count)
        plt.imshow(x[:, :, z], cmap="gist_heat")
        plt.axis("off")
        count += 1
#+END_SRC

#+LABEL: section_example
#+CAPTION: Esempio di immagine. Essendo una figura tridimensionale, si rappresenta la profondità con più immagini.
#+RESULTS:
[[file:images/sample.png]]


Mentre le dimensioni dei /voxel/ sono fisse per tutti i file, l'immagine è ritagliata sulla lesione in modo specifico, tralasciando le parti adiacenti: le dimensioni variano in base alla dimensione della lesione stessa.

#+BEGIN_SRC python :session :exports results :results dataframe :rownames yes :colnames no
dim_x = x_1.GetMetaData("pixdim[1]")
dim_y = x_1.GetMetaData("pixdim[1]")
dim_z = x_1.GetMetaData("pixdim[1]")

res = pd.DataFrame({"x":[round(float(dim_x), 3)],
                    "y":[round(float(dim_y), 3)],
                    "z":[round(float(dim_z), 3)]},
                   index = ["voxel size"])

res.T
#+END_SRC

#+RESULTS:
:    voxel size
: x       2.734
: y       2.734
: z       2.734

Dunque sarà importante estrarre delle /features/ che non dipendano dalla dimensione dell'immagine ma tengano conto di possibili variazioni.
Questo approccio comporta una serie di vantaggi, primo tra tutti la modularità del /workflow/: è possibile così prevedere la variabile risposta avendo a disposizione sia un'immagine già segmentata sia effettuando la segmentazione /on-the-fly/ tramite semplici algoritmi a soglia, riducendo potenzialmente il tempo della diagnosi.

* Estrazione delle /features/
L'estrazione delle /features/ mappa le immagini in uno spazio di dimensionalità molto minore e di dimensioni fisse, rendendo più semplice l'analisi dato il numero esiguo di dati a disposizione.
Infatti, un qualsiasi algoritmo di /machine learning/ ha bisogno di un numero significativo di dati per  ``apprendere'' in modo /data-driven/ cosa utilizzare nell'analisi.

Per selezionare le /features/ da utilizzare, si è preso spunto da cite:imaging[fn::Gli autori usano i primi quattro momenti per stimare la differenza di eterogeneità di tumori alla cervicale nel tempo, a seguito di un trattamento.] e cite:gallivanone18_param_influen_pet_imagin_featur: si usano /features/ estratte direttamente dall'immagine, quali superficie della lesione o la sua sfericità, accompagnate da indici statistici più semplici quali i momenti di ordine dal primo fino al quarto (media, varianza, asimmetria e curtosi) dei valori dei singoli /voxel/ (tabella [[tbl_features]]).

#+BEGIN_SRC R :session :tangle yes :exports none :results none
rm(list = ls())
set.seed(20200623)
#+END_SRC

#+BEGIN_SRC R :session :tangle yes :exports none :results none
library(tidyverse)

features <- readr::read_csv("./feature_dataset.csv")
features <- features %>%
  mutate_at(setdiff(colnames(features),
                    c("y")),
            ~(scale(.) %>% as.vector))
features <- features[sample(nrow(features)), ]
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :rownames no :colnames yes
round(head(features[, 1:4]), 3)
#+END_SRC

#+LABEL: tbl_features
#+CAPTION: Esempio di /features/ estratte per le singole immagini.
#+RESULTS:
| VoxelNum | Maximum3DDiameter | MajorAxisLength | Sphericity |
|----------+-------------------+-----------------+------------|
|   -1.337 |            -4.107 |          -3.071 |      1.116 |
|   -0.036 |             0.727 |            0.35 |     -0.381 |
|    0.458 |             0.118 |          -0.106 |      0.956 |
|    0.192 |             0.745 |            0.71 |     -0.546 |
|   -0.654 |              0.14 |           0.664 |     -0.124 |
|   -0.329 |            -0.508 |          -0.692 |      0.607 |


Tuttavia il numero di /features/ estratte è ancora elevato rispetto al numero di dati a disposizione (la matrice di /input/ ha dimensioni $44 \times 24$).
Si effettua dunque una prima selezione delle /features/ tramite il test di Mann-Whitney, equivalente non parametrico del t-test (i risultati sono riassunti nella tabella [[tbl_mann_whitney]]), per escludere le variabili la cui significatività, prese singolarmente, è minore del 5%.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
score <- c()
for (i in seq(1, dim(features)[2] - 1)) {
  formula <- paste0(colnames(features)[i], " ~ y")
  t_score <- wilcox.test(formula = as.formula(formula),
                         data = features)$p.value
  score <- c(score, round(t_score, 3))
}
score_df <- data.frame(t(score))
colnames(score_df) <- colnames(features)[1:(dim(features)[2] - 1)]
accepted <- colnames(score_df[, score_df < 0.05])

features <- features[, c(accepted, "y")]
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :rownames yes
t(score_df[, accepted])
#+END_SRC

#+LABEL: tbl_mann_whitney
#+CAPTION: p-value delle varibili accetate dal test di Mann-Whitney.
#+RESULTS:
| Maximum3DDiameter | 0.011 |
| MajorAxisLength   | 0.012 |
| Sphericity        | 0.003 |
| MinorAxisLength   | 0.003 |
| SurfaceArea       | 0.016 |
| Kurtosis          | 0.002 |
| Maximum           | 0.008 |
| Skewness          |  0.04 |
| Variance          | 0.025 |
| Contrast          |  0.02 |
| ngtdm_Coarseness  | 0.034 |

Effettuata questa prima cernita, si riduce ulteriormente il numero di /features/, in modo tale da evitare multi-collinearità tra le variabili, rispettando così le premesse del modello lineare.

#+BEGIN_SRC R :session :exports results :results file graphics :file images/corrplot.png
library(ggcorrplot)


ggcorrplot::ggcorrplot(
              cor(features),
              type = "lower",
              outline.col = "white",
              lab = TRUE)
#+END_SRC

#+LABEL: features_corr
#+CAPTION: Correlogramma delle /features/ estratte.
#+RESULTS:
[[file:images/corrplot.png]]

Dal correlogramma (figura [[features_corr]]) si deduce quali variabili escludere (=Maximum=, =Variance=, =Maximum3DDiameter=, =MinorAxisLength=, =Contrast= e =Sphericity=): la matrice risultante ha una dimensionalità ridotta ($44 \times 5$), adeguata per la costruzione del modello.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
new_cols <- setdiff(colnames(features),
                    c("Maximum", "Variance",
                      "Maximum3DDiameter",
                      "MinorAxisLength",
                      "Contrast", "Sphericity"))

features <- features[, new_cols]
#+END_SRC


* Modello /supervised/
Essendo la variabile risposta binaria (tumore /omogeneo/ o /eterogeneo/, rispettivamente 0 o 1), e volendo costruire un modello facilmente interpretabile per un esperto di dominio, si effettua una semplice regressione logistica.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
library(MASS)


formula <- stepAIC(glm(y ~  MajorAxisLength + SurfaceArea + Kurtosis +
                            Skewness + ngtdm_Coarseness,
                       data = features,
                       family = binomial("logit")),
                   direction = "both",
                   k = log(nrow(features)))$formula
mod_full <- glm(formula, data = features, family = binomial("logit"))
#+END_SRC

La selezione delle /features/ è effettuata tramite procedimento /stepwise/ usando l'indice BIC[fn::L'indice BIC rispetto all'indice AIC penalizza maggiormente l'inserimento di una nuova variabile con un numero ridotto di osservazioni.], con possibilità di re-immissione.
Il numero di variabili significative si riduce quindi a tre: =SurfaceArea=, =Kurtosis= e =Skewness= (riassunti nella tabella [[tbl_model_coeff]] coi rispettivi p-value).

#+BEGIN_SRC R :session :exports results :results tabular :colnames yes :rownames yes
df <- summary(mod_full)$coefficients[, c(1, 4)]
colnames(df) <- c("Stima", "p-value")
round(df, 6)
#+END_SRC

#+LABEL: tbl_model_coeff
#+CAPTION: Stima dei coefficienti del modello e loro significatività.
#+RESULTS:
|             |      Stima |  p-value |
|-------------+------------+----------|
| (Intercept) |  -4.295873 | 0.014587 |
| SurfaceArea | -11.899879 | 0.005449 |
| Kurtosis    |  -9.842963 | 0.008876 |
| Skewness    |  -8.655905 | 0.007367 |

#+COMMENT: TODO analisi dei risultati

#+BEGIN_SRC R :session :tangle yes :exports none :results none
accuracy <- function(y_true, y_hat) {
  return(mean(y_true == y_hat))
}

precision <- function(y_true, y_hat) {
  tp <- mean(y_hat == 1 & y_true == 1)
  fp <- mean(y_hat == 1 & y_true == 0)
  return(tp / (tp + fp))
}

recall <- function(y_true, y_hat) {
  tp <- mean(y_hat == 1 & y_true == 1)
  fn <- mean(y_hat == 0 & y_true == 1)
  if (fn == 0) return(1)
  return(tp / (tp + fn))
}

f1 <- function(y_true, y_hat) {
  p <- precision(y_true, y_hat)
  r <- recall(y_true, y_hat)
  return(2 * p * r / (p + r))
}

features$y <- as.factor(features$y)
k <- 30
dim_fold <- 9
out <- list(accuracy = c(),
            precision = c(),
            recall = c(),
            f_1 = c())

for (i in seq(1, k)) {
  set.seed(i)
  test_index <- sample(seq(1, dim(features)[1]), dim_fold)
  train_set <- features[-test_index, ]
  test_set  <- features[ test_index, ]

  mod <- glm(formula,
             data = train_set,
             family = binomial("logit"))

  y_hat <- ifelse(predict(mod, test_set) > 0.5, 1, 0)
  y_true <- test_set$y
  out$accuracy  <- c(out$accuracy,  accuracy(y_true, y_hat))
  out$precision <- c(out$precision, precision(y_true, y_hat))
  out$recall    <- c(out$recall,    recall(y_true, y_hat))
  out$f_1       <- c(out$f_1,       f1(y_true, y_hat))
}
#+END_SRC

Le prestazioni del modello sono calcolate col sistema /cross validation/, effettuando 30 iterazioni casuali dividendo i dati 80% /train set/ e 20% /test set/, così da avere stime robuste dei parametri e un intervallo di confidenza sufficientemente ristretto.
La media degli indici di bontà è riportata nella tabella [[supervised_results]] assieme al rispettivo intervallo di confidenza al 99%.

#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
out_df <- data.frame(index = c("accuracy", "precision", "recall", "f_1"))
scores <- c()
idc <- c()
for (index in out_df$index) {
  score <- out[[index]]
  score <- score[!is.nan(score)]
  mu <- mean(score)
  s  <- sd(score)
  d <- qt(0.99, length(score) - 1) * s / sqrt(length(score))
  scores <- c(scores, mu)
  idc <- c(idc, d)
}
out_df$average <- scores
out_df$IDC_99   <- idc
rownames(out_df) <- out_df$index
round(out_df[, c("average", "IDC_99")], 3)
#+END_SRC

#+LABEL: supervised_results
#+CAPTION: Performance del modello supervisionato con intervallo di confidenza al 99%.
#+RESULTS:
|           | average | IDC_99 |
|-----------+---------+--------|
| accuracy  |   0.893 |   0.04 |
| precision |   0.932 |  0.054 |
| recall    |    0.89 |  0.059 |
| f_1       |   0.899 |  0.041 |

Si calcola quindi anche la matrice di confusione (tabella [[supervised_confusion_matrix]]), e si nota che l'unico errore è stato commesso catalogando come eterogenea una variabile omogenea.

#+BEGIN_SRC R :session :exports results :results tabular :colnames yes :rownames yes
previsions <- data.frame(prevision = ifelse(predict(mod, test_set) > 0.5,
                                            "prediction: heterogeneous",
                                            "prediction: homogeneous"),
                         real = ifelse(test_set$y == 1,
                                       "heterogeneous",
                                       "homogeneous"))
conf_matrix <- table(previsions)
#+END_SRC

#+LABEL: supervised_confusion_matrix
#+CAPTION: Matrice di confusione del modello di regressione logistica per il /test set/; sulle righe le previsioni e sulle colonne i valori reali.
#+RESULTS:
|                           | heterogeneous | homogeneous |
|---------------------------+---------------+-------------|
| prediction: heterogeneous |             4 |           1 |
| prediction: homogeneous   |             0 |           4 |

* Modello /unsupervised/
Considerando tutti i dati (quindi più informazione possibile), standardizzati, si effettua una divisione in /clusters/ con l'ipotesi che sia possibile raggruppare le due tipologie di tumore.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
features <- readr::read_csv("./feature_dataset.csv")
features <- features %>%
  mutate_at(setdiff(colnames(features),
                    c("y")),
            ~(scale(.) %>% as.vector))
features$y <- as.factor(features$y)
#+END_SRC

Le immagini di tumori quindi sono collocate in uno spazio vettoriale in base al risultato della /Principal Component Analysis/ (PCA): si selezionano così le prime 6 componenti, che assieme spiegano circa il 95% della varianza totale della distribuzione.
Così, oltre a operare su una matrice di dimensioni ridotte, si riduce anche la quantità di rumore data dall'elevato numero di variabili (a cui si esclude la variabile risposta =y=, usata poi per calcolare la bontà del modello) spesso inutili.
Dalla figura [[fig:pca_plot]] infatti si vede che all'aumentare del numero di componenti considerate, la percentuale di varianza colta aumenta con un tasso decrescente: la soglia del 95% è un compromesso tra il segnale colto dal modello e la sua complessità (per i dettagli vedere la tabella [[table_pca]]).


#+BEGIN_SRC R :session :exports results :results graphics file :file images/pca_unsupervised.png
eigen_values <- eigen(var(features))$values
perc_variance <- cumsum(eigen_values) / sum(eigen_values)

data.frame(number_of_components = seq(1, dim(features)[2]),
           variance=perc_variance) %>%
  ggplot(aes(x = number_of_components, y = variance)) +
  geom_line() + geom_point(size = 3) +
  # geom_hline(aes(yintercept = 1), alpha = 0.3) +
  geom_hline(aes(yintercept = 0.95), color = "red",
             alpha = 0.4) +
  xlab("Number of Components") + ylab("% variance") +
  ggtitle("Selection of number of components of PCA") +
  theme_minimal()
#+END_SRC

#+LABEL: fig:pca_plot
#+CAPTION: Andamento della varianza spiegata dal modello all'aumentare del numero di componenti della PCA.
#+RESULTS:
[[file:images/pca_unsupervised.png]]

#+BEGIN_SRC R :session :tangle yes :exports none :results none
unsupervised_features <- features[, 1:(dim(features)[2] - 1)]
data.pca <- prcomp(unsupervised_features)
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :colnames yes :rownames yes
round(summary(data.pca)$importance[, 1:6], 3)
#+END_SRC

#+LABEL: table_pca
#+CAPTION: Alcune statistiche sulle prime componenti principali.
#+RESULTS:
|                        |   PC1 |   PC2 |   PC3 |   PC4 |   PC5 |   PC6 |
|------------------------+-------+-------+-------+-------+-------+-------|
| Standard deviation     | 3.454 | 2.188 | 1.824 | 1.122 | 0.941 | 0.728 |
| Proportion of Variance | 0.497 | 0.199 | 0.139 | 0.052 | 0.037 | 0.022 |
| Cumulative Proportion  | 0.497 | 0.696 | 0.835 | 0.887 | 0.924 | 0.946 |


Nello spazio della PCA si effettua un raggruppamento usando l'algoritmo DBScan, basato sulla densità delle osservazioni.
La figura [[fig:DBScan_eps]] suggerisce un parametro $\varepsilon = 3.5$ (con 5-NN): questa configurazione sarà usata per la costruzione del modello.


# Si effettua un primo tipo di clustering basato sulla densita' (nello spazio dei PCA) usando uno dei modelli piu' usati per il clustering, il DBScan. Nella Figura [[fig:DBScan_eps]] notiamo che eps piu' vantaggioso usando la distanza di 5-NN risulta vicino al 3.5, quindi viene scelto esso come il valore ideale, per il clustering.

#+BEGIN_SRC R :session :exports results :results graphics file :file images/dbscan_eps_selection.png
data <- data.pca$x[, 1:6]

dbscan::kNNdistplot(data, k = 5)
abline(h = 3.5, lty = 2, col = "red")
#+END_SRC

#+LABEL: fig:DBScan_eps
#+CAPTION: Scelta del valore $\varepsilon$ per DBScan.
#+RESULTS:
[[file:images/dbscan_eps_selection.png]]

#+BEGIN_SRC R :session :tangle yes :exports none :results none
data <- data.pca$x[,1:6]

cluster <- dbscan::dbscan(data, 3.5)
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :rownames yes
out <- data.frame("accuracy"  = accuracy(cluster$cluster, features$y),
                  "precision" = precision(cluster$cluster, features$y),
                  "recall"    = recall(cluster$cluster, features$y),
                  "f_1"       = f1(cluster$cluster, features$y))
round(t(out), 3)
#+END_SRC

#+LABEL: dbscan_performance
#+CAPTION: Indici di bontà per la clusterizzazione con DBScan.
#+RESULTS:
| accuracy  | 0.773 |
| precision | 0.962 |
| recall    | 0.735 |
| f_1       | 0.833 |


#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
HomOrHet <- ifelse(features$y==0, "homogeneous", "heterogeneous")
clus <- paste0("C_", cluster$cluster)
table(clus, HomOrHet)
#+END_SRC

#+LABEL: dbscan_confusion_matrix
#+CAPTION: Distribuzione delle immagini all'interno dei /clusters/.
#+RESULTS:
|     | heterogeneous | homogeneous |
|-----+---------------+-------------|
| C_0 |             1 |           9 |
| C_1 |            25 |           9 |

Nonostante le buone /performance/ del modello (riassunte nella tabella [[dbscan_performance]]), si nota che il secondo /cluster/ $C_1$ contiene un numero non indifferente di immagini omogenee.
Infatti l'algoritmo è riuscito a individuare un solo /cluster/ ($C_0$) ben definito, considerando la variabile risposta.

Si tenta quindi un altro approccio, con l'algoritmo /HK-means/, versione gerarchica del ben più noto /K-means/.
L'algoritmo è quindi testato con un numero di /cluster/ $k$ da 2 a 15, calcolando per ciascuno la distanza nei gruppi (/distance between/).
La figura [[fig:kmean_k]] mostra graficamente il procedimento: si sceglie $k = 4$ per evitare /overfitting/ dei dati, e siccome il tasso di aumento per $k > 4$ decresce fortemente.
La bontà del raggruppamento invece (intesa come capacità predittiva) è riassunta nella tabella
[[hkmeans_performance]].

# Pur avendo un'accuratezza non bassa, si vede che il secondo cluster contiene un numero di immagini omogenee non trascurabili, inoltre il DBScan e' riuscito a trovare solo un cluster, il /CLUSTER_0/ e' un cluster costituito da prova considerate non appartenenti a nessun cluster.
# Quindi si tenta un altro approccio basato su un ibrido tra il clustering gerarchico e il k-means.

#+BEGIN_SRC R :session :tangle yes :results none :exports none
ncluster_score <- c()
for (num_clus in seq(2, 15)){
  cluster <- factoextra::hkmeans(data, num_clus)
  # Calculate silhuoette based on the mode of the cluster.
  ncluster_score <- c(ncluster_score,
                      cluster$betweenss)
}
#+END_SRC


# In questo caso pero' bisogna cercare il numero di cluster ideale, e per fare questo effettiamo il cluster per ciascun k da 2 da 15 e plottiamo le loro misure betweenss e scegliamo un k in base al plot.
# Nella Figura [[fig:kmean_k]] scegliamo il k=4 per non ``overfittare'' il cluster.

#+BEGIN_SRC R :session :exports results :results graphics file :file images/cluster_selection.png
data.frame(number_of_cluster = seq(2, 15),
           sil = ncluster_score) %>%
  ggplot(aes(x = number_of_cluster, y = ncluster_score)) +
  geom_line() + geom_point() +
  geom_vline(aes(xintercept = 4), color="red",
             alpha=0.4) +
  xlab("Number of Clusters K") + ylab("Distance Between") +
  ggtitle("Selection of number of cluster") +
  theme_minimal()
#+END_SRC

#+LABEL: fig:kmean_k
#+CAPTION: Variazione della distanza /between/ all'aumentare del parametro $k$.
#+RESULTS:
[[file:images/cluster_selection.png]]


# Nella tabella seguente si mostrano le misure ottentute dal cluster.

#+BEGIN_SRC R :session :exports results :results table :rownames yes
cluster <- factoextra::hkmeans(data, 4, iter.max = 50)
tp <- 0
tn <- 0
fp <- 0
fn <- 0
for (i in seq(1,4)){
  index <- which(cluster$cluster == i)
  in_clus <- features$y[index]
  homs <- as.numeric(table(in_clus)["0"])
  hets <- as.numeric(table(in_clus)["1"])
  if (homs > hets){
    tn <- tn + homs
    fp <- fp + hets
  } else {
    tp <- tp + hets
    fn <- fn + homs
  }
}
accuracy <- (tp + tn) / (tp + fn + fp + tn)
recall <- tp / (tp + fn)
precision <- tp / (tp + fp)
f1 <- 2 * recall * precision / (recall + precision)

round(data.frame(c(accuracy, precision, recall, f1),
           row.names=c("accuracy", "precision",
                       "recall", "f_1")),3)
#+END_SRC

#+LABEL: hkmeans_performance
#+CAPTION: Indici di bontà per HK-Means con $k = 4$.
#+RESULTS:
| accuracy  | 0.727 |
| precision |     1 |
| recall    | 0.684 |
| f1-score  | 0.813 |

#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
HomOrHet <- ifelse(features$y == 0, "homogeneous", "heterogeneous")
clus <- paste0("C_", cluster$cluster)
table(clus, HomOrHet)
#+END_SRC

#+LABEL: hkmeans_clusters
#+CAPTION: Il modello ha identificato 3 /cluster/ definiti (C_3, C_4 e C_5), considerando la variabile risposta; mentre la maggior parte delle osservazioni è compresa tra i primi due /cluster/ (C_1 e C_2).
#+RESULTS:
|     | heterogeneous | homogeneous |
|-----+---------------+-------------|
| C_1 |            18 |           8 |
| C_2 |             8 |           4 |
| C_3 |             0 |           4 |
| C_4 |             0 |           2 |

# Anche il questo caso il cluster ottiene performance decenti, ma il primo modello riusciva a distinguire le due immagini in una maniera piu' decente e con meno cluster.

Nonostante le buone prestazioni, a confronto col modello DBScan non si hanno forti miglioramenti: infatti il modello precedente ha una capacità predittiva maggiore e una complessità minore.
Nonostante questo, la capacità predittiva dei modelli /unsupervised/, paragonati a quello /supervised/ presentato precedentemente, è nettamente inferiore.
Inoltre, lavorando nello spazio delle componenti principali, l'interpretabilità del modello risulta difficile anche per un esperto di dominio.


* Conclusioni
Con questo Progetto si è costruito un modello statistico /supervised/ efficace e facilmente interpretabile da un esperto di dominio per prevedere l'eterogeneità del tumore.
Per costruirlo è stato sufficiente estrapolare dalle immagini segmentate delle semplici /features/, veloci da calcolare e facili da interpretare.
Si è quindi confrontato questo modello con uno /unsupervised/, confermando la superiorità del primo sia per bontà di previsione sia per facilità di interpretazione.

Per migliorare il modello si potrebbe, a livello teorico, usare un numero maggiore di dati per la stima dei parametri e per selezionare le /features/ da includere; tuttavia questo non è sempre possibile in ambito medico, data la forte difficoltà e l'alto costo nell'ottenere una più grande quantità di dati.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
summary(mod_full)
#+END_SRC


* Bibliografia :ignore:
#+LATEX: \newpage
#+LATEX: \nocite{*}
bibliographystyle:unsrt
bibliography:./bibliografia.bib
#+BEGIN_SRC bibtex :tangle bibliografia.bib :exports none
@article{imaging,
  author = {Bowen, Stephen and
            Yuh, William and
            Hippe, Daniel and
            Wu, Wei and
            Partridge, Savannah and
            Elias, Saba and
            Jia, Guang and
            Huang, Zhibin and
            Sandison, George and
            Nelson, Dennis and
            Knopp, Michael and
            Lo, Simon and
            Kinahan, Paul and
            Mayr, Nina},
  year = {2017},
  month = {10},
  pages = {},
  title = {Tumor radiomic heterogeneity: Multiparametric functional imaging to characterize variability and predict response following cervical cancer radiation therapy},
  volume = {47},
  journal = {Journal of Magnetic Resonance Imaging},
  doi = {10.1002/jmri.25874}
}

@article{gallivanone18_param_influen_pet_imagin_featur,
  author          = {Francesca Gallivanone and
                     Matteo Interlenghi and
                     Daniela D'Ambrosio and
                     Giuseppe Trifirò and
                     Isabella Castiglioni},
  title           = {Parameters Influencing Pet Imaging Features: a Phantom Study With Irregular and Heterogeneous Synthetic Lesions},
  journal         = {Contrast Media \& Molecular Imaging},
  volume          = {2018},
  number          = {},
  pages           = {1-12},
  year            = {2018},
  doi             = {10.1155/2018/5324517},
  url             = {https://doi.org/10.1155/2018/5324517},
  DATE_ADDED      = {Thu Jun 11 16:47:03 2020},
}
#+END_SRC
#+begin_comment
Local variables:
org-latex-caption-above: nil
eval: (pyvenv-activate (concat (getenv "HOME") "/.anaconda/envs/medical"))
eval: (ispell-change-dictionary "italiano")
End:
#+end_comment

* Anaconda Environment :noexport:
Run =conda env create --file anaconda_environment.yml= to create the environment.
#+BEGIN_SRC yaml :tangle anaconda_environment.yml
name: medical
dependencies:
- python=3.7
- pandas=1.0.4
- numpy=1.18.5
- matplotlib=3.2.1
- simpleitk=1.2.4
- pywavelets=1.0.0
- r-base=4.0.0
- r-mass=7.3_51.6
- r-tidyverse=1.3.0
- r-ggcorrplot=0.1.3
- r-dbscan=1.1_5
- r-factoextra=1.0.7
- pip:
  - pyradiomics==3.0
#+END_SRC

#+BEGIN_SRC bash :tangle execute-all.sh
conda activate medical || \
    (conda env create --file anaconda_environment.yml && conda activate medical)
echo "Extracting features..."
python main.py
echo "Training model..."
R -f main.R
#+END_SRC
