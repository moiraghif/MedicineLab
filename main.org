#+TITLE: *Big Data in Health Care*
#+AUTHOR: Federico Moiraghi - 799735 & Pranav Kasela - 846965
#+DATE: A.A. 2019/2020
#+OPTIONS: toc:nil
#+LANGUAGE: it

#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper, 12pt]

* Abstract :ignore:
#+begin_abstract
Obiettivo del presente Progetto è di fornire due modelli predittivi che riescano a riconoscere i tumori omogenei da quelli eterogenei.
Infatti l'eterogeneità del tumore rappresenta una difficoltà aggiuntiva nella fase di trattamento, rendendolo maggiormente resistente alle cure.
Il primo modello, /supervised/, sarà facilmente interpretabile da un esperto di dominio, in modo tale da supportare le sue decisioni senza sostituirsi completamente ad esso.
Tale modello sarà poi confrontato con uno /unsupervised/, anch'esso di facile interpretazione, che sottolinea le analogie tra i singoli casi.
#+end_abstract

* Indice :ignore:

#+TOC: headlines 1
#+LATEX: \thispagestyle{empty}
#+LATEX: \newpage


* Introduzione
Si è deciso di sviluppare il presente Progetto coi linguaggi di programmazione Python ed R, data la forte crescita del loro uso sia in ambiente accademico che produttivo.
Il primo è usato soprattutto per l'estrazione delle /features/ dalle immagini, grazie alla libreria [[https://github.com/Radiomics/pyradiomics][=pyradiomics=]], mentre il secondo per l'analisi dei dati, data l'ampia disponibilità di modelli di /machine learning/ già implementati.

#+BEGIN_SRC python :session :tangle yes :exports none :results none
import pandas as pd
from radiomics import featureextractor

#nii image reader
import SimpleITK as sitk
import numpy as np

import multiprocessing as mp
import os

#indicating the features required
extract_this = {"shape":      ["Maximum3DDiameter",
                               "MajorAxisLength", "Sphericity",
                               "MinorAxisLength", "SurfaceArea",
                               "SurfaceVolumeRatio",
                               "Flatness", "VoxelVolume"],
                "firstorder": ["Entropy", "Kurtosis", "Maximum",
                               "MeanAbsoluteDeviation",
                               "Mean", "Median", "Minimum",
                               "MeanAbsoluteDeviation",
                               "Skewness", "Variance"],
                # "glcm":       ["Autocorrelation", "Contrast"],  # TODO: uncomment
                # "glrlm":      ["HighGrayLevelRunEmphasis"],     # TODO: uncomment
                "ngtdm":      ["Contrast", "Coarseness"]}

#initialize the featureextractor and define the required features
extractor = featureextractor.RadiomicsFeatureExtractor()
extractor.disableAllFeatures()
extractor.enableFeaturesByName(**extract_this)

features = ["diagnostics_Mask-original_VoxelNum"]
features_name = ["VoxelNum"]
for key in extract_this.keys():
    for elem in extract_this.get(key):
        features.append("original_" + key + "_" + elem)
        if key == "ngtdm":
            features_name.append(key + "_" + elem)
        else:
            features_name.append(elem)

features_name.append("y")

homImagePath = "./code__esempi/lesions/homogeneous/nifti/"
homImages = [(homImagePath+file, 1) for file in os.listdir(homImagePath)]

hetImagePath = "./code__esempi/lesions/heterogeneous/nifti/"
hetImages = [(hetImagePath+file, 0) for file in os.listdir(hetImagePath)]

images = homImages + hetImages

def get_feature_df(path):
    img    = sitk.ReadImage(path[0])
    mask   = img > 0
    infos  = extractor.execute(img, mask)
    result = [float(infos[f]) for f in features]
    result.append(path[1])
    return result

#some parallelization
pool = mp.Pool(4)
res = pool.map(get_feature_df, images)

#the final df
final_df = pd.DataFrame(res, columns=features_name)

# final_df.to_csv("feature_dataset.csv", index=None)  # TODO: uncomment
#+END_SRC

Caricate le immagini (si ha un esempio con figura [[section_example]]), si nota che queste rappresentano la lesione già segmentata.
Non si ritiene dunque necessaria alcuna forma particolare di /pre-processing/ sull'immagine.

#+BEGIN_SRC python :session :exports results :results file graphics :file images/sample.png
import matplotlib.pyplot as plt


x_1 = sitk.ReadImage(hetImages[14][0])
x = sitk.GetArrayFromImage(x_1)

fig = plt.figure()
count = 1
for z in range(x.shape[2]):
    if z > 4 and z < 14:
        plt.subplot(3, 3, count)
        plt.imshow(x[:, :, z], cmap="gist_heat")
        plt.axis("off")
        count += 1
#+END_SRC

#+LABEL: section_example
#+CAPTION: Esempio di immagine. Essendo una figura tridimensionale, si rappresenta la profondità con più immagini.
#+RESULTS:
[[file:images/sample.png]]


Mentre le dimensioni dei /voxel/ sono fisse per tutti i files, l'immagine è ritagliata sulla lesione in modo specifico, tralasciando le parti adiacenti: le dimensioni variano in base alla dimensione della lesione stessa.

#+BEGIN_SRC python :session :exports results :results dataframe :rownames yes :colnames no
dim_x = x_1.GetMetaData("pixdim[1]")
dim_y = x_1.GetMetaData("pixdim[1]")
dim_z = x_1.GetMetaData("pixdim[1]")

res = pd.DataFrame({"x":[round(float(dim_x), 3)],
                    "y":[round(float(dim_y), 3)],
                    "z":[round(float(dim_z), 3)]},
                   index = ["voxel size"])

res.T
#+END_SRC

#+RESULTS:
:    voxel size
: x       2.734
: y       2.734
: z       2.734

Dunque sarà importante estrarre delle /features/ che non dipendano dalla dimensione dell'immagine ma tengano conto di possibili variazioni.
Questo approccio comporta una serie di vantaggi, primo tra tutti la modularità del /workflow/: è possibile così prevedere la variabile risposta avendo a disposizione sia un'immagine già segmentata sia effettuando la segmentazione /on-the-fly/ tramite semplici algoritmi a soglia, riducendo potenzialmente il tempo della diagnosi.

* Estrazione delle /features/
L'estrazione delle /features/ mappa le immagini in uno spazio di dimensionalità molto minore e di dimensioni fisse, rendendo più semplice l'analisi dato il numero esiguo di dati a disposizione.
Infatti, un qualsiasi algoritmo di /machine learning/ ha bisogno di un numero significativo di dati per  ``apprendere'' in modo /data-driven/ cosa utilizzare nell'analisi.

Per selezionare le /features/ da utilizzare, si è preso spunto da cite:imaging[fn::Gli autori usano i primi quattro momenti per stimare la differenza di eterogeneità di tumori alla cervicale nel tempo, a seguito di un trattamento.] e cite:gallivanone18_param_influen_pet_imagin_featur: si usano /features/ estratte direttamente dall'immagine, quali superficie della lesione o la sua sfericità, accompagnate da indici statistici più semplici quali i momenti dal primo fino al quarto (media, varianza, asimmetria e curtosi) dei valori dei singoli /voxel/ (tabella [[tbl_features]]).

#+BEGIN_SRC R :session :tangle yes :exports none :results none
rm(list = ls())
set.seed(20200623)
#+END_SRC

#+BEGIN_SRC R :session :tangle yes :exports none :results none
library(tidyverse)

features <- readr::read_csv("./feature_dataset.csv")
features <- features %>%
  mutate_at(setdiff(colnames(features),
                    c("y")),
            ~(scale(.) %>% as.vector))
features <- features[sample(nrow(features)), ]
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :rownames no :colnames yes
round(head(features[, 1:4]), 3)
#+END_SRC

#+LABEL: tbl_features
#+CAPTION: Esempio di /features/ estratte per le singole immagini.
#+RESULTS:
| VoxelNum | Maximum3DDiameter | MajorAxisLength | Sphericity |
|----------+-------------------+-----------------+------------|
|   -1.337 |            -4.107 |          -3.071 |      1.116 |
|   -0.036 |             0.727 |            0.35 |     -0.381 |
|    0.458 |             0.118 |          -0.106 |      0.956 |
|    0.192 |             0.745 |            0.71 |     -0.546 |
|   -0.654 |              0.14 |           0.664 |     -0.124 |
|   -0.329 |            -0.508 |          -0.692 |      0.607 |


Tuttavia il numero di /features/ estratte è ancora elevato rispetto al numero di dati a disposizione (la matrice di /input/ ha dimensioni $44 \times 24$).
Si effettua dunque una prima selezione delle /features/ tramite il test di Mann-Whitney, equivalente non parametrico del t-test (i risultati sono riassunti nella tabella [[tbl_mann_whitney]]), per escludere le variabili la cui significatività da sole è minore del 5%.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
score <- c()
for (i in seq(1, dim(features)[2] - 1)) {
  formula <- paste0(colnames(features)[i], " ~ y")
  t_score <- wilcox.test(formula=as.formula(formula),
                         data=features)$p.value
  score <- c(score, round(t_score, 3))
}
score_df <- data.frame(t(score))
colnames(score_df) <- colnames(features)[1:(dim(features)[2] - 1)]
accepted <- colnames(score_df[,score_df < 0.05])

features <- features[, c(accepted, "y")]
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :rownames yes
t(score_df[, accepted])
#+END_SRC

#+LABEL: tbl_mann_whitney
#+CAPTION: p-value delle varibili accetate dal test di Mann-Whitney.
#+RESULTS:
| Maximum3DDiameter | 0.011 |
| MajorAxisLength   | 0.012 |
| Sphericity        | 0.003 |
| MinorAxisLength   | 0.003 |
| SurfaceArea       | 0.016 |
| Kurtosis          | 0.002 |
| Maximum           | 0.008 |
| Skewness          |  0.04 |
| Variance          | 0.025 |
| Contrast          |  0.02 |
| ngtdm_Coarseness  | 0.034 |

Effettuata questa prima cernita, si riduce ulteriormente il numero di /features/, in modo tale da evitare multi-collinearità tra le variabili, rispettando in tal modo le premesse del modello lineare.

#+BEGIN_SRC R :session :exports results :results file graphics :file images/corrplot.png
library(ggcorrplot)


ggcorrplot::ggcorrplot(
              cor(features),
              type = "lower",
              outline.col = "white",
              lab = TRUE)
#+END_SRC

#+LABEL: features_corr
#+CAPTION: Correlogramma delle /features/ estratte.
#+RESULTS:
[[file:images/corrplot.png]]

Dalla figura [[features_corr]], si deduce quali variabili escludere ( =Maximum=, =Variance=, =Maximum3DDiameter=, =MinorAxisLength=, =Contrast= e =Sphericity=): la matrice risultante ha così dimensioni $44 \times 5$, dimensionalità adeguata per la costruzione del modello.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
new_cols <- setdiff(colnames(features),
                    c("Maximum", "Variance",
                      "Maximum3DDiameter",
                      "MinorAxisLength",
                      "Contrast", "Sphericity"))

features <- features[, new_cols]
#+END_SRC
* Modello /supervised/
Essendo la variabile risposta binaria (tumore /omogeneo/ o /eterogeneo/, rispettivamente 0 o 1), e volendo costruire un modello facilmente interpretabile per un esperto di dominio, si effettua una semplice regressione logistica.

#+BEGIN_SRC R :session :tangle yes :exports none :results none
library(MASS)


formula <- stepAIC(glm(y ~  MajorAxisLength + SurfaceArea + Kurtosis +
                            Skewness + ngtdm_Coarseness,
                       data = features,
                       family = binomial("logit")),
                   direction = "both",
                   k = log(nrow(features)))$formula
mod_full <- glm(formula, data = features, family = binomial("logit"))
#+END_SRC

#+BEGIN_SRC R :session :tangle yes :exports none :results none
accuracy <- function(y_true, y_hat) {
  return(mean(y_true == y_hat))
}

precision <- function(y_true, y_hat) {
  tp <- mean(y_hat == 1 & y_true == 1)
  fp <- mean(y_hat == 1 & y_true == 0)
  return(tp / (tp + fp))
}

recall <- function(y_true, y_hat) {
  tp <- mean(y_hat == 1 & y_true == 1)
  fn <- mean(y_hat == 0 & y_true == 1)
  if (fn == 0) return(1)
  return(tp / (tp + fn))
}

f1 <- function(y_true, y_hat) {
  p <- precision(y_true, y_hat)
  r <- recall(y_true, y_hat)
  return(2 * p * r / (p + r))
}

features$y <- as.factor(features$y)
k <- 30
dim_fold <- 9
out <- list(accuracy = c(),
            precision = c(),
            recall = c(),
            f_1 = c())

for (i in seq(1, k)) {
  set.seed(i)
  test_index <- sample(seq(1,dim(features)[1]), dim_fold)
  train_set <- features[-test_index, ]
  test_set  <- features[ test_index, ]

  mod <- glm(formula,
             data = train_set,
             family = binomial("logit"))

  y_hat <- ifelse(predict(mod, test_set) > 0.5, 1, 0)
  y_true <- test_set$y
  out$accuracy <- c(out$accuracy, accuracy(y_true, y_hat))
  out$precision <- c(out$precision, precision(y_true, y_hat))
  out$recall <- c(out$recall, recall(y_true, y_hat))
  out$f_1 <- c(out$f_1, f1(y_true, y_hat))
}
#+END_SRC
#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
out_df <- data.frame(index = c("accuracy", "precision", "recall", "f_1"))
scores <- c()
idc <- c()
for (index in out_df$index) {
  score <- out[[index]]
  score <- score[!is.nan(score)]
  mu <- mean(score)
  s  <- sd(score)
  d <- qt(0.99, length(score) - 1) * s / sqrt(length(score))
  scores <- c(scores, mu)
  idc <- c(idc, d)
}
out_df$average <- scores
out_df$IDC_99   <- idc
rownames(out_df) <- out_df$index
round(out_df[, c("average", "IDC_99")], 3)
#+END_SRC

#+RESULTS:
|           | average | IDC_99 |
|-----------+---------+--------|
| accuracy  |   0.893 |   0.04 |
| precision |   0.932 |  0.054 |
| recall    |    0.89 |  0.059 |
| f_1       |   0.899 |  0.041 |

La selezione delle /features/ è effettuata tramite procedimento /stepwise/ (partendo dal modello pieno ed eliminando le variabili superflue, ma con la possibilità, a ogni iterazione, di reinserirle).
Si è deciso di rimuovere alcune variabili a prescindere:
- =sd= (la varianza della distribuzione della lesione), in quanto fortemente correlata con =mean= (0.93) e di più difficile interpretazione;
- =area= (la superficie della lesione), in quanto la sua stima è approssimativa e risulta essere eccessivamente correlata ad altri regressori, inquinando eccessivamente la qualità dei dati;
- =sphere= (il volume della sfera equivalente), data la sua forte correlazione con la variabile =volume= (0.86) e la più difficile interpretabilità.
#+LATEX: \newline
Avendo a disposizione pochi dati, il procedimento è effettuato con l'indice AIC, che considera la capacità di generalizzazione del modello complessivo risultante (salvo poi verificare le /performance/ su un /test set/ composto da dati nuovi, rappresentante circa il 20% di quelli totali).
Alla fine del procedimento, il modello risultante comprende solo tre regressori (più l'intercetta), come mostrato in tabella [[tbl_model_coeff]].

#+BEGIN_SRC R :session :exports results :results tabular :colnames yes :rownames yes
df <- summary(mod_full)$coefficients[, c(1, 4)]
colnames(df) <- c("Stima", "p-value")
round(df, 6)
#+END_SRC

#+LABEL: tbl_model_coeff
#+CAPTION: Stima dei coefficienti del modello e loro significatività.
#+RESULTS:
|             |      Stima |  p-value |
|-------------+------------+----------|
| (Intercept) |  -4.295873 | 0.014587 |
| SurfaceArea | -11.899879 | 0.005449 |
| Kurtosis    |  -9.842963 | 0.008876 |
| Skewness    |  -8.655905 | 0.007367 |


Si noti come i coefficienti maggiormente significativi siano l'asimmetria =sk= e il volume =volume=: la probabilità che il tumore sia eterogeneo è tanto maggiore quanto più grande è la lesione e quanto più pesante è la coda positiva della distribuzione.
Si può ipotizzare infatti che questa coda positiva sia costituita da sotto-componenti particolarmente aggressivi del tumore, quindi ``ghiotti'' di traccianti e di conseguenza maggiormente visibili nell'immagine.

#+BEGIN_SRC R :session :exports results :results tabular :colnames yes :rownames yes
previsions <- data.frame(prevision = ifelse(predict(mod, test_set) > 0.5,
                                            "heterogeneous",
                                            "homogeneous"),
                         real = ifelse(test_set$y == 1,
                                       "heterogeneous",
                                       "homogeneous"))
conf_matrix <- table(previsions)
#+END_SRC

#+LABEL: mod_confusion_matrix
#+CAPTION: Matrice di confusione del modello di regressione logistica per il /test set/; sulle righe le previsioni e sulle colonne i valori reali.
#+RESULTS:
|               | heterogeneous | homogeneous |
|---------------+---------------+-------------|
| heterogeneous |             4 |           0 |
| homogeneous   |             1 |           4 |


Come si può notare nella matrice di confusione (figura [[mod_confusion_matrix]]), il modello ha commesso un solo errore catalogando come eterogenea una lesione omogenea.

#+BEGIN_SRC R :session :exports results :results tabular :rownames yes
out_accuracy  <- sum(diag(conf_matrix)) / sum(conf_matrix)
out_precision <- conf_matrix["heterogeneous", "heterogeneous"] /
                      sum(conf_matrix["heterogeneous", ])
out_recall    <- conf_matrix["heterogeneous", "heterogeneous"] /
                      sum(conf_matrix[, "heterogeneous"])
out_f1        <- 2 * (out_precision * out_recall) / (out_precision + out_recall)
round(c("accuracy" = out_accuracy,
        "precision" = out_precision,
        "recall" = out_recall,
        "f_1" = out_f1), 2)
#+END_SRC

#+RESULTS:
| accuracy  | 0.89 |
| precision |    1 |
| recall    |  0.8 |
| f_1       | 0.89 |

#+LABEL: mod_results
#+CAPTION: Indici di accuratezza per il modello.
#+RESULTS:

* Modello /semi-supervised/ o /unsupervised/

#+BEGIN_SRC R :session :tangle yes :exports none :results none
features <- readr::read_csv("./feature_dataset.csv")
features <- features %>%
  mutate_at(setdiff(colnames(features),
                    c("y")),
            ~(scale(.) %>% as.vector))
features$y <- as.factor(features$y)
#+END_SRC

Riprendiamo il dataset di partenza senza alcun feature selection, e effettiamo solo una standardizzazione. Per effettuare il clustering si devono diminuire le dimensioni, non volendo usare le y (se non per il calcolo dell'accuratezza) non possiamo usare i soliti modelli di feture selection, un modo potrebbe essere effettuare una feature selection basata sulla varianza, e per fare cio' si effetua la PCA, accettando solo le PCA che spiegano circa il $95\%$ della varianza delle variabili di partenza. Nella figura [[fig:pca_plot]] si vede che 6 componenti del PCA spiegano il $95\%$ della varianza, in questo modo si elimina anche molto rumore che e' causato dalla presenza di tante variabili (spesso inutili).

#+BEGIN_SRC R :session :exports results :results graphics file :file images/pca_unsupervised.png
eigen_values <- eigen(var(features))$values
perc_variance <- cumsum(eigen_values) / sum(eigen_values)
data.frame(number_of_components = seq(1, dim(features)[2]),
           variance=perc_variance) %>%
  ggplot(aes(x=number_of_components, y=variance)) +
  geom_line() + geom_point() +
  geom_hline(aes(yintercept = 1), alpha=0.3) +
  geom_hline(aes(yintercept = 0.95), color="red",
             alpha=0.4) +
  xlab("Number of PC") + ylab("% variance") +
  ggtitle("Selection of number of components of PCA")
#+END_SRC

#+LABEL: fig:pca_plot
#+CAPTION: Plot della varianza cumulativa con le dimensioni di PCA.
#+RESULTS:
[[file:images/pca_unsupervised.png]]


#+BEGIN_SRC R :session :tangle yes :exports none :results table :colnames yes :rownames yes
unsupervised_features <- features[, 1:(dim(features)[2] - 1)]
data.pca <- prcomp(unsupervised_features)

round(summary(data.pca)$importance[, 1:6], 3)
#+END_SRC

#+RESULTS:
|                        |   PC1 |   PC2 |   PC3 |   PC4 |   PC5 |   PC6 |
|------------------------+-------+-------+-------+-------+-------+-------|
| Standard deviation     | 2.995 |  2.02 | 1.814 | 1.095 | 0.901 | 0.684 |
| Proportion of Variance | 0.448 | 0.204 | 0.165 |  0.06 | 0.041 | 0.023 |
| Cumulative Proportion  | 0.448 | 0.652 | 0.817 | 0.877 | 0.917 | 0.941 |


Si effettua un primo tipo di clustering basato sulla densita' (nello spazio dei PCA) usando uno dei modelli piu' usati per il clustering, il DBScan. Nella Figura [[fig:DBScan_eps]] notiamo che eps piu' vantaggioso usando la distanza di 5-NN risulta vicino al 3.5, quindi viene scelto esso come il valore ideale, per il clustering.

#+BEGIN_SRC R :session :exports results :results graphics file :file images/dbscan_eps_selection.png
data <- data.pca$x[,1:6]

dbscan::kNNdistplot(data, k=5)
abline(h = 3.5, lty = 2, col="red")
#+END_SRC

#+LABEL: fig:DBScan_eps
#+CAPTION: Scelta del eps per il DBScan
#+RESULTS:
[[file:images/dbscan_eps_selection.png]]

#+BEGIN_SRC R :session :tangle yes :exports none :results none
data <- data.pca$x[,1:6]

cluster <- dbscan::dbscan(data, 3.5)
#+END_SRC

#+BEGIN_SRC R :session :exports results :results table :rownames yes
out <- data.frame("accuracy"  = accuracy(cluster$cluster, features$y),
                  "precision" = precision(cluster$cluster, features$y),
                  "recall"    = recall(cluster$cluster, features$y),
                  "f_1"       = f1(cluster$cluster, features$y))
round(t(out), 2)
#+END_SRC
#+CAPTION: Results on the DBScan cluster.
#+RESULTS:
| accuracy  | 0.75 |
| precision | 0.96 |
| recall    | 0.71 |
| f_1       | 0.82 |

#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
HomOrHet <- ifelse(features$y==0, "HOM", "HET")
clus <- paste0("CLUSTER_", cluster$cluster)
table(clus, HomOrHet)
#+END_SRC
#+CAPTION: Distribution of the images in the cluster.
#+RESULTS:
|           | HET | HOM |
|-----------+-----+-----|
| CLUSTER_0 |   1 |   8 |
| CLUSTER_1 |  25 |  10 |


Pur avendo un'accuratezza non bassa, si vede che il secondo cluster contiene un numero di immagini omogenee non trascurabili, inoltre il DBScan e' riuscito a trovare solo un cluster, il /CLUSTER_0/ e' un cluster costituito da prova considerate non appartenenti a nessun cluster.
Quindi si tenta un altro approccio basato su un ibrido tra il clustering gerarchico e il k-means.


#+BEGIN_SRC R :session :results none :exports none
ncluster_score <- c()
for (num_clus in seq(2,15)){
  cluster <- factoextra::hkmeans(data, num_clus)
  # Calculate silhuoette based on the mode of the cluster.
  ncluster_score <- c(ncluster_score,
                      cluster$betweenss)
}
#+END_SRC

In questo caso pero' bisogna cercare il numero di cluster ideale, e per fare questo effettiamo il cluster per ciascun k da 2 da 15 e plottiamo le loro misure betweenss e scegliamo un k in base al plot.
Nella Figura [[fig:kmean_k]] scegliamo il k=4 per non ``overfittare'' il cluster.

#+BEGIN_SRC R :session :exports results :results graphics file :file images/cluster_selection.png
data.frame(number_of_cluster = seq(2, 15),
           sil=ncluster_score) %>%
  ggplot(aes(x=number_of_cluster, y=ncluster_score)) +
  geom_line() + geom_point() +
  geom_vline(aes(xintercept = 4), color="red",
             alpha=0.4) +
  xlab("Number of Clusters") + ylab("BetweenSS") +
  ggtitle("Selection of number of cluster")
#+END_SRC
#+LABEL: fig:kmean_k
#+CAPTION: Plot of the BetweenSS for each k to chose the optimal one.
#+RESULTS:
[[file:images/cluster_selection.png]]

Nella tabella seguente si mostrano le misure ottentute dal cluster.

#+BEGIN_SRC R :session :exports results :results table :rownames yes
cluster <- factoextra::hkmeans(data, 4, iter.max=50)
tp <- 0
tn <- 0
fp <- 0
fn <- 0
for (i in seq(1,4)){
  index <- which(cluster$cluster == i)
  in_clus <- features$y[index]
  homs <- as.numeric(table(in_clus)["0"])
  hets <- as.numeric(table(in_clus)["1"])
  if (homs > hets){
    tn <- tn + homs
    fp <- fp + hets
  } else {
    tp <- tp + hets
    fn <- fn + homs
  }
}
accuracy <- (tp+tn)/(tp+fn+fp+tn)
recall <- tp/(tp+fn)
precision <- tp/(tp+fp)
f1 <- 2*recall*precision/(recall+precision)

round(data.frame(c(accuracy, precision, recall, f1),
           row.names=c("accuracy","precision",
                       "recall","f1-score")),3)
#+END_SRC

#+RESULTS:
| accuracy  | 0.727 |
| precision |     1 |
| recall    | 0.684 |
| f1-score  | 0.813 |

#+BEGIN_SRC R :session :exports results :results table :rownames yes :colnames yes
HomOrHet <- ifelse(features$y==0, "HOM", "HET")
clus <- paste0("CLUSTER_", cluster$cluster)
table(clus, HomOrHet)
#+END_SRC

#+RESULTS:
|           | HET | HOM |
|-----------+-----+-----|
| CLUSTER_1 |  18 |   8 |
| CLUSTER_2 |   8 |   4 |
| CLUSTER_3 |   0 |   2 |
| CLUSTER_4 |   0 |   4 |

Anche il questo caso il cluster ottiene performance decenti, ma il primo modello riusciva a distinguire le due immagini in una maniera piu' decente e con meno cluster.

* Conclusioni
Con questo Progetto si è costruito un modello statistico efficace e facilmente interpretabile da un esperto di dominio per prevedere l'eterogeneità del tumore.
Si è visto che, estrapolando dall'immagine dei semplici valori indice, è possibile costruire un modello indipendente dalla dimensione dell'immagine o dalla sua risoluzione.
#+LATEX: \newline
A livello matematico si potrebbe aumentare la prestazione del modello stimando i parametri con un numero maggiore di dati; tuttavia, in ambito medico, questo non è sempre possibile (anche perché, come espresso in cite:imaging, è possibile verificare l'eterogeneità del tumore solo in modo invasivo o con autopsia).
Inoltre si potrebbero utilizzare nuove /features/, soprattutto se utili ai fini della ricerca medica.
#+BEGIN_SRC R :session :tangle yes :exports none :results none
summary(mod_full)
#+END_SRC


* Bibliografia :ignore:
#+LATEX: \newpage
#+LATEX: \nocite{*}
bibliographystyle:unsrt
bibliography:./bibliografia.bib
#+BEGIN_SRC bibtex :tangle bibliografia.bib :exports none
@article{imaging,
  author = {Bowen, Stephen and
            Yuh, William and
            Hippe, Daniel and
            Wu, Wei and
            Partridge, Savannah and
            Elias, Saba and
            Jia, Guang and
            Huang, Zhibin and
            Sandison, George and
            Nelson, Dennis and
            Knopp, Michael and
            Lo, Simon and
            Kinahan, Paul and
            Mayr, Nina},
  year = {2017},
  month = {10},
  pages = {},
  title = {Tumor radiomic heterogeneity: Multiparametric functional imaging to characterize variability and predict response following cervical cancer radiation therapy},
  volume = {47},
  journal = {Journal of Magnetic Resonance Imaging},
  doi = {10.1002/jmri.25874}
}

@article{gallivanone18_param_influen_pet_imagin_featur,
  author          = {Francesca Gallivanone and
                     Matteo Interlenghi and
                     Daniela D'Ambrosio and
                     Giuseppe Trifirò and
                     Isabella Castiglioni},
  title           = {Parameters Influencing Pet Imaging Features: a Phantom Study With Irregular and Heterogeneous Synthetic Lesions},
  journal         = {Contrast Media \& Molecular Imaging},
  volume          = {2018},
  number          = {},
  pages           = {1-12},
  year            = {2018},
  doi             = {10.1155/2018/5324517},
  url             = {https://doi.org/10.1155/2018/5324517},
  DATE_ADDED      = {Thu Jun 11 16:47:03 2020},
}
#+END_SRC
#+begin_comment
Local variables:
org-latex-caption-above: nil
eval: (pyvenv-activate (concat (getenv "HOME") "/.anaconda/envs/medical"))
eval: (ispell-change-dictionary "italiano")
End:
#+end_comment

* Anaconda Environment :noexport:
Run =conda env create --file anaconda_environment.yml= to create the environment.
#+BEGIN_SRC yaml :tangle anaconda_environment.yml
name: medical
dependencies:
- python=3.7
- pandas=1.0.4
- numpy=1.18.5
- matplotlib=3.2.1
- simpleitk=1.2.4
- pywavelets=1.0.0
- r-base=4.0.0
- r-mass=7.3_51.6
- r-tidyverse=1.3.0
- r-ggcorrplot=0.1.3
- r-dbscan=1.1_5
- r-factoextra=1.0.7
- pip:
  - pyradiomics==3.0
#+END_SRC

#+BEGIN_SRC bash :tangle execute-all.sh
conda activate medical || \
    (conda env create --file anaconda_environment.yml && conda activate medical)
echo "Extracting features..."
python main.py
echo "Training model..."
R -f main.R
#+END_SRC
